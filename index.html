<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>3D Gaussian Splatting - Real-Time Pose Estimation</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px auto;
      max-width: 1000px;
      line-height: 1.6;
      color: #222;
    }
    h1, h2, h3 {
      color: #003366;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 1rem 0;
      border: 1px solid #ddd;
    }
    .caption {
      font-size: 0.9em;
      color: #666;
      text-align: center;
      margin-top: -10px;
    }
  </style>
</head>
<body>
  <h1>3D Gaussian Splatting for Real-Time Pose Estimation and Tracking of Dynamic Objects</h1>
  <p><strong>Authors:</strong> Saurabh Vidyarthi, Joji Joseph, Siddharth S Desai, Sahil Bobade, Bharadwaj Amrutur<br>
  <strong>Institute:</strong> Indian Institute of Science, Bangalore, India</p>

  <h2>Abstract</h2>
  <p>We present a training-free pipeline that updates the pose of moving objects within a 3D Gaussian Splatting (3DGS) scene in real time using only a monocular RGB camera. The method avoids costly retraining by adjusting only the mean and orientation of the Gaussians belonging to dynamic objects, enabling low-latency digital twin updates for robotics, mixed reality, and industrial monitoring.</p>

  <h2>Pipeline Overview</h2>
  <img src="ex_03.jpg" alt="Pipeline Diagram">
  <p class="caption">Figure 1: Overview of the proposed real-time 3DGS dynamic update pipeline.</p>

  <h2>Semantic Embedding</h2>
  <p>We use Gradient-Weighted Feature Back-Projection to embed semantic features into each 3D Gaussian. This enhances object detection and scene understanding during pose updates.</p>

  <h2>Tracking Pipeline</h2>
  <img src="final_output.png" alt="Tracking Pipeline">
  <p class="caption">Figure 2: Pose adjustment using rendered and test-field views.</p>

  <h2>Examples of Real-Time Tracking</h2>
  <img src="ex_01.png" alt="Person Tracking Example 1">
  <img src="ex_02.jpg" alt="Person Tracking Example 2">
  <img src="ex_03.drawio.png" alt="Person Tracking Example 3">
  <img src="main_poinmap_flow.jpg" alt="Person and Robot Tracking">
  <img src="graph.jpg" alt="Accuracy Graph">
  <p class="caption">Figure 3: Accuracy over time and qualitative examples of person and robot tracking.</p>

  <h2>Results</h2>
  <p>The system achieves mean translational error of 52 cm for objects with 8.5 m displacement using only monocular input. The entire update loop runs in under 3.5 seconds on an RTX A6000 GPU.</p>

  <h2>Conclusion</h2>
  <p>This work shows that 3DGS can be extended for real-time, drift-free, and training-free tracking of dynamic objects using a single RGB camera, enabling high-fidelity dynamic digital twins for practical deployment.</p>

</body>
</html>
